{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RPN_11.3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fydaijian/test_faster-r-cnn/blob/master/RPN_11_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt6cj5wywg7B",
        "colab_type": "code",
        "outputId": "5d1c6594-62dc-4fb9-f5d7-d4d330443705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxeMZooWY5-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "8914f4fc-41a4-4937-cc1c-b2191c692810"
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Nov  6 12:20:54 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW9V7iQAZTNp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ3EIIGj3YIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "da84c449-623b-467c-8f85-6562078864d4"
      },
      "source": [
        "path = \"/content/gdrive/My Drive\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Getting started.pdf',\n",
              " 'Colab Notebooks',\n",
              " '无标题文件夹',\n",
              " 'VOC2007',\n",
              " 'Getting started.gdoc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP-AVAiasTJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "folderpath =  \"VOC2007\"\n",
        "trainval_percent = 0.66\n",
        "train_percent = 0.5\n",
        "xmlfilepath = 'VOC2007/Annotations'\n",
        "txtsavepath = 'VOC2007/ImageSets/Main'\n",
        "total_xml = os.listdir(xmlfilepath)\n",
        "num = len(total_xml)\n",
        "list = range(num)\n",
        "tv = int(num*trainval_percent)\n",
        "tr = int(tv*train_percent)\n",
        "trainval = random.sample(list,tv)\n",
        "train = random.sample(trainval,tr)\n",
        "ftrainval = open(folderpath + '/ImageSets/Main/trainval.txt', 'w')\n",
        "ftest = open(folderpath + '/ImageSets/Main/test.txt', 'w')\n",
        "ftrain = open(folderpath + '/ImageSets/Main/train.txt', 'w')\n",
        "fval = open(folderpath + '/ImageSets/Main/val.txt', 'w')\n",
        "for i in list:\n",
        "    name = total_xml[i][:-4]+'\\n'\n",
        "    if i in trainval:\n",
        "        ftrainval.write(name)\n",
        "        if i in train:\n",
        "            ftrain.write(name)\n",
        "        else:\n",
        "            fval.write(name)\n",
        "    else:\n",
        "        ftest.write(name)\n",
        "ftrainval.close()\n",
        "ftrain.close()\n",
        "fval.close()\n",
        "ftest .close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8BoEwgXw7s7",
        "colab_type": "code",
        "outputId": "c0590fb5-2683-4f67-f1b1-d54b8d76ead6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "def get_data(input_path):\n",
        "    all_imgs = []\n",
        "    classes_count = {}\n",
        "    class_mapping = {}\n",
        "\n",
        "    # parsing 정보 확인 Flag\n",
        "    visualise = False\n",
        "\n",
        "    # pascal voc directory + 2012\n",
        "    data_paths = [os.path.join(input_path, 'VOC2007')]\n",
        "\n",
        "    print('Parsing annotation files')\n",
        "    for data_path in data_paths:\n",
        "\n",
        "        annot_path = os.path.join(data_path, 'Annotations')\n",
        "        imgs_path = os.path.join(data_path, 'JPEGImages')\n",
        "\n",
        "        #ImageSets/Main directory의 4개 파일(train, val, trainval, test)\n",
        "        imgsets_path_trainval = os.path.join(data_path, 'ImageSets', 'Main', 'trainval.txt')\n",
        "        imgsets_path_train = os.path.join(data_path, 'ImageSets', 'Main', 'train.txt')\n",
        "        imgsets_path_val = os.path.join(data_path, 'ImageSets', 'Main', 'val.txt')\n",
        "        imgsets_path_test = os.path.join(data_path, 'ImageSets', 'Main', 'test.txt')\n",
        "\n",
        "        trainval_files = []\n",
        "        train_files = []\n",
        "        val_files = []\n",
        "        test_files = []\n",
        "\n",
        "        with open(imgsets_path_trainval) as f:\n",
        "            for line in f:\n",
        "                trainval_files.append(line.strip() + '.jpg')\n",
        "\n",
        "        with open(imgsets_path_train) as f:\n",
        "            for line in f:\n",
        "                train_files.append(line.strip() + '.jpg')\n",
        "\n",
        "        with open(imgsets_path_val) as f:\n",
        "            for line in f:\n",
        "                val_files.append(line.strip() + '.jpg')\n",
        "\n",
        "        # test-set not included in pascal VOC 2012\n",
        "        if os.path.isfile(imgsets_path_test):\n",
        "            with open(imgsets_path_test) as f:\n",
        "                for line in f:\n",
        "                    test_files.append(line.strip() + '.jpg')\n",
        "\n",
        "        # 이미지셋 txt 파일 read 예외처리\n",
        "        # try:\n",
        "        #     with open(imgsets_path_trainval) as f:\n",
        "        #         for line in f:\n",
        "        #             trainval_files.append(line.strip() + '.jpg')\n",
        "        # except Exception as e:\n",
        "        #     print(e)\n",
        "        #\n",
        "        # try:\n",
        "        #     with open(imgsets_path_test) as f:\n",
        "        #         for line in f:\n",
        "        #             test_files.append(line.strip() + '.jpg')\n",
        "        # except Exception as e:\n",
        "        #     if data_path[-7:] == 'VOC2012':\n",
        "        #         # this is expected, most pascal voc distibutions dont have the test.txt file\n",
        "        #         pass\n",
        "        #     else:\n",
        "        #         print(e)\n",
        "\n",
        "        # annotation 파일 read\n",
        "        annots = [os.path.join(annot_path, s) for s in os.listdir(annot_path)]\n",
        "        idx = 0\n",
        "\n",
        "        annots = tqdm(annots)\n",
        "        for annot in annots:\n",
        "            # try:\n",
        "            exist_flag = False\n",
        "            idx += 1\n",
        "            annots.set_description(\"Processing %s\" % annot.split(os.sep)[-1])\n",
        "\n",
        "            et = ET.parse(annot)\n",
        "            element = et.getroot()\n",
        "\n",
        "            element_objs = element.findall('object')\n",
        "            # element_filename = element.find('filename').text + '.jpg'\n",
        "            element_filename = element.find('filename').text\n",
        "            element_width = int(element.find('size').find('width').text)\n",
        "            element_height = int(element.find('size').find('height').text)\n",
        "\n",
        "            if len(element_objs) > 0:\n",
        "                annotation_data = {'filepath': os.path.join(imgs_path, element_filename), 'width': element_width,\n",
        "                                   'height': element_height, 'bboxes': []}\n",
        "\n",
        "                annotation_data['image_id'] = idx\n",
        "\n",
        "                if element_filename in trainval_files:\n",
        "                    annotation_data['imageset'] = 'trainval'\n",
        "                    exist_flag = True\n",
        "\n",
        "                if element_filename in train_files:\n",
        "                    annotation_data['imageset'] = 'train'\n",
        "                    exist_flag = True\n",
        "\n",
        "                if element_filename in val_files:\n",
        "                    annotation_data['imageset'] = 'val'\n",
        "                    exist_flag = True\n",
        "\n",
        "                if len(test_files) > 0:\n",
        "                    if element_filename in test_files:\n",
        "                        annotation_data['imageset'] = 'test'\n",
        "                        exist_flag = True\n",
        "\n",
        "                    # if element_filename in trainval_files:\n",
        "                    #     annotation_data['imageset'] = 'trainval'\n",
        "                    # elif element_filename in test_files:\n",
        "                    #     annotation_data['imageset'] = 'test'\n",
        "                    # else:\n",
        "                    #     annotation_data['imageset'] = 'trainval'\n",
        "\n",
        "            # annotation file not exist in ImageSet\n",
        "            if not exist_flag:\n",
        "                continue\n",
        "\n",
        "            for element_obj in element_objs:\n",
        "                class_name = element_obj.find('name').text\n",
        "                if class_name not in classes_count:\n",
        "                    classes_count[class_name] = 1\n",
        "                else:\n",
        "                    classes_count[class_name] += 1\n",
        "\n",
        "                # class mapping 정보 추가\n",
        "                if class_name not in class_mapping:\n",
        "                    class_mapping[class_name] = len(class_mapping)  # 마지막 번호로 추가\n",
        "\n",
        "                obj_bbox = element_obj.find('bndbox')\n",
        "                x1 = int(round(float(obj_bbox.find('xmin').text)))\n",
        "                y1 = int(round(float(obj_bbox.find('ymin').text)))\n",
        "                x2 = int(round(float(obj_bbox.find('xmax').text)))\n",
        "                y2 = int(round(float(obj_bbox.find('ymax').text)))\n",
        "                difficulty = int(element_obj.find('difficult').text) == 1\n",
        "                annotation_data['bboxes'].append(\n",
        "                    {'class': class_name, 'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2, 'difficult': difficulty})\n",
        "            all_imgs.append(annotation_data)\n",
        "\n",
        "            if visualise:\n",
        "                img = cv2.imread(annotation_data['filepath'])\n",
        "                for bbox in annotation_data['bboxes']:\n",
        "                    cv2.rectangle(img, (bbox['x1'], bbox['y1']), (bbox['x2'], bbox['y2']), (0, 0, 255))\n",
        "                cv2.imshow('img', img)\n",
        "                print(annotation_data['imageset'])\n",
        "                cv2.waitKey(0)\n",
        "\n",
        "            # except Exception as e:\n",
        "            #     print(e)\n",
        "            #     continue\n",
        "    return all_imgs, classes_count, class_mapping\n",
        "def save_obj(obj,name):\n",
        "    with open('obj/'+name+\".pkl\",\"wb\") as f:\n",
        "        pickle.dump(obj,f,pickle.HIGHEST_PROTOCOL)\n",
        "def load_obj(name ):\n",
        "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "if __name__==\"__main__\":\n",
        "    img_data=get_data('/content/gdrive/My Drive')[0]\n",
        "    save_obj(img_data,\"test_1\")\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 007977.xml:   0%|          | 0/4958 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Parsing annotation files\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing 001889.xml: 100%|██████████| 4958/4958 [26:26<00:00,  3.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5e4b3215064a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mimg_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-5e4b3215064a>\u001b[0m in \u001b[0;36msave_obj\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'obj/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'obj/test_1.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G2cqOE9hxXIj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "bbec2dbc-b92b-4d39-c6b4-8b707a4e4dbc"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import copy\n",
        "def anchor_gen(ratios, scales,resize_image=(224,224),featureMap_size=(14,14),anchor_stride=1):\n",
        "  '''\n",
        "  boxes=[x1,y1,x2,y2]\n",
        "  '''\n",
        "    rpn_stride=int(resize_image[0]/featureMap_size[0])\n",
        "    # ratios, scales = np.meshgrid(ratios, scales)\n",
        "    # ratios, scales = ratios.flatten(), scales.flatten()\n",
        "    point=[]\n",
        "    width_heigh=[]\n",
        "    boxes=[]\n",
        "    for ix in np.arange(featureMap_size[1]):\n",
        "      for iy in np.arange(featureMap_size[0]):\n",
        "        point.append((ix*rpn_stride,iy*rpn_stride))\n",
        "    for scale in scales:\n",
        "      for ratio in ratios:\n",
        "        width = scale/ np.sqrt(ratio)\n",
        "        height = scale * np.sqrt(ratio)\n",
        "        width_heigh.append((width,height))\n",
        "    \n",
        "    for ix,iy in point:\n",
        "        for ratio_W_H in width_heigh:\n",
        "          width,height=ratio_W_H[0],ratio_W_H[1]\n",
        "          coordinate=np.array([ix- width,iy-height,ix+ width,iy+height])\n",
        "          boxes.append(coordinate)\n",
        "\n",
        "    boxes=np.array(boxes)\n",
        "    return boxes\n",
        "anchors=anchor_gen(ratios = [0.5, 1, 1.5],scales = [4, 8, 16])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ -5.65685425  -2.82842712   5.65685425   2.82842712]\n",
            " [ -4.          -4.           4.           4.        ]\n",
            " [ -3.26598632  -4.89897949   3.26598632   4.89897949]\n",
            " ...\n",
            " [185.372583   196.6862915  230.627417   219.3137085 ]\n",
            " [192.         192.         224.         224.        ]\n",
            " [194.93605471 188.40408206 221.06394529 227.59591794]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK4XJI-uLJnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accord_bbox(img_data,*input_network):\n",
        "    resized_width,resized_height=input_network\n",
        "    num_bboxes=len(img_data[\"bboxes\"])\n",
        "    width=img_data[\"width\"]\n",
        "    height=img_data[\"height\"]\n",
        "    gta = np.zeros((num_bboxes, 4))\n",
        "    for bbox_num, bbox in enumerate(img_data['bboxes']):\n",
        "        # get the GT box coordinates, and resize to account for image resizing\n",
        "        gta[bbox_num, 0] = bbox['x1'] * (resized_width / float(width))\n",
        "        gta[bbox_num, 2] = bbox['x2'] * (resized_width / float(width))\n",
        "        gta[bbox_num, 1] = bbox['y1'] * (resized_height / float(height))\n",
        "        gta[bbox_num, 3] = bbox['y2'] * (resized_height / float(height))\n",
        "    gta_bbox=gta\n",
        "    return gta_bbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTOKyPe-MGUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_iou(box, boxes, area, areas):\n",
        "  '''\n",
        "  box:anchor\n",
        "  boxes: boxes\n",
        "  '''\n",
        "    y1 = np.maximum(box[0], boxes[:, 0])\n",
        "    x1 = np.maximum(box[1], boxes[:, 1])\n",
        "    y2 = np.minimum(box[2], boxes[:, 2])\n",
        "    x2 = np.minimum(box[3], boxes[:, 3])\n",
        "    interSec = np.maximum(y2-y1, 0) * np.maximum(x2-x1, 0)\n",
        "    union = areas[:] + area - interSec\n",
        "    iou = interSec / union\n",
        "    return iou\n",
        "def compute_overlap(boxes1, boxes2):\n",
        "  '''\n",
        "  boxes1:anchors\n",
        "  boxes2:groundTruth\n",
        "  '''\n",
        "    areas1 = (boxes1[:,3] - boxes1[:,1]) * (boxes1[:,2] - boxes1[:,0])\n",
        "    areas2 = (boxes2[:,3] - boxes2[:,1]) * (boxes2[:,2] - boxes2[:,0])\n",
        "    overlap = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n",
        "    for i in range(boxes2.shape[0]):\n",
        "        box = boxes2[i]\n",
        "        overlap[:,i] = compute_iou(box, boxes1, areas2[i], areas1)\n",
        "    return overlap\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5B16EFKS5A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_rpnTarget(boxes, anchors, config):\n",
        "    rpn_match = np.zeros(anchors.shape[0], dtype=np.int32)\n",
        "    rpn_bboxes = np.zeros((config.train_rois_num, 4))\n",
        "\n",
        "    iou = compute_overlap(anchors, boxes)\n",
        "    maxArg_iou = np.argmax(iou, axis=1)\n",
        "    max_iou = iou[np.arange(iou.shape[0]), maxArg_iou]\n",
        "    postive_anchor_idxs = np.where(max_iou > 0.4)[0]\n",
        "    negative_anchor_idxs = np.where(max_iou < 0.1)[0]\n",
        "\n",
        "    rpn_match[postive_anchor_idxs] = 1\n",
        "    rpn_match[negative_anchor_idxs] = -1\n",
        "    maxIou_anchors = np.argmax(iou, axis=0)\n",
        "    rpn_match[maxIou_anchors] = 1\n",
        "\n",
        "    ids = np.where(rpn_match == 1)[0]\n",
        "    extral = len(ids) - config.train_rois_num // 2\n",
        "    if extral > 0:\n",
        "        ids_ = np.random.choice(ids, extral, replace=False)\n",
        "        rpn_match[ids_] = 0\n",
        "\n",
        "    ids = np.where(rpn_match == -1)[0]\n",
        "    extral = len(ids) - (config.train_rois_num - np.where(rpn_match == 1)[0].shape[0])\n",
        "    if extral > 0:\n",
        "        ids_ = np.random.choice(ids, extral, replace=False)\n",
        "        rpn_match[ids_] = 0\n",
        "\n",
        "    idxs = np.where(rpn_match == 1)[0]\n",
        "    ix = 0\n",
        "    for i, a in zip(idxs, anchors[idxs]):\n",
        "        gt = boxes[maxArg_iou[i]]\n",
        "\n",
        "        gt_h = gt[2] - gt[0]\n",
        "        gt_w = gt[3] - gt[1]\n",
        "        gt_centy = gt[0] + 0.5 * gt_h\n",
        "        gt_centx = gt[1] + 0.5 * gt_w\n",
        "\n",
        "        a_h = a[2] - a[0]\n",
        "        a_w = a[3] - a[1]\n",
        "        a_centy = a[0] + 0.5 * a_h\n",
        "        a_centx = a[1] + 0.5 * a_w\n",
        "\n",
        "        rpn_bboxes[ix] = [(gt_centy - a_centy) / a_h, (gt_centx - a_centx) / a_w,\n",
        "                          np.log(gt_h / a_h), np.log(gt_w / a_w)]\n",
        "        rpn_bboxes[ix] /= config.RPN_BBOX_STD_DEV\n",
        "        ix += 1\n",
        "    return rpn_match, rpn_bboxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUoRNoFk7vH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "b6b8a5f4-4960-400c-ba9e-6ca3ea67924e"
      },
      "source": [
        "anchors=anchor_gen(ratios = [0.5, 1, 2],scales = [4, 8, 16])\n",
        "print(anchors)\n",
        "\n",
        "print(anchors.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0]\n",
            " [  0  16]\n",
            " [  0  32]\n",
            " ...\n",
            " [208 176]\n",
            " [208 192]\n",
            " [208 208]]\n",
            "(1764, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}